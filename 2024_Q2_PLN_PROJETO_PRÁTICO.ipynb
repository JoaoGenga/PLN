{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2024-Q2]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m67OOx9MX_3"
      },
      "source": [
        "### **PROJETO PRÁTICO** [LangChain + Grandes Modelos de Linguagem + API]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gk0nHKabBT-"
      },
      "source": [
        "O **PROJETO PRÁTICO** deve ser feitO utilizando o **Google Colab** com uma conta sua vinculada ao Gmail. O link do seu notebook, armazenado no Google Drive, o link de um repositório no GitHub e o link de um vídeo do projeto em execução detalhando os principais resultados da atividade, devem ser enviados usando o seguinte formulário:\n",
        "\n",
        "> https://forms.gle/D4gLqP1iGgyn2hbH8\n",
        "\n",
        "\n",
        "**IMPORTANTE**: A submissão deve ser feita até o dia **08/09 (domingo)** APENAS POR UM INTEGRANTE DA EQUIPE, até às 23h59. Por favor, lembre-se de dar permissão de ACESSO IRRESTRITO para o professor da disciplina de PLN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7hJlilKM485"
      },
      "source": [
        "### **EQUIPE**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**POR FAVOR, PREENCHER OS INTEGRANDES DA SUA EQUIPE:**\n",
        "\n",
        "\n",
        "**Integrante 01:**\n",
        "\n",
        "`Por favor, informe o seu nome completo e RA:` Vitor Inacio da Silva 11201810048\n",
        "\n",
        "**Integrante 02:**\n",
        "\n",
        "`Por favor, informe o seu nome completo e RA:` João Pedro Genga Carneiro 11201810740"
      ],
      "metadata": {
        "id": "tnIArN0QY-Ek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GRANDE MODELO DE LINGUAGEM (*Large Language Model - LLM*)**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "VbYD2mw8y4CN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cada equipe deve selecionar um Grande Modelo de Linguagem (*Large Language Model - LMM*). Cada modelo pode ser escolhido por até 5 equipes.\n",
        "\n"
      ],
      "metadata": {
        "id": "_UlblxFxzDV-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por favor, informe os dados do LLM selecionada:\n",
        "\n",
        ">\n",
        "\n",
        "\n",
        "**LLM**: Google Gemini 1.5 flash\n",
        "\n",
        ">\n",
        "\n",
        "**Link para a documentação oficial**: https://ai.google.dev/gemini-api?hl=pt-br\n",
        "\n"
      ],
      "metadata": {
        "id": "a6AkE6iW0c3o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **API**\n",
        "---"
      ],
      "metadata": {
        "id": "6yExhaebs-nD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por favor, informe os dados da API selecionada:\n",
        "\n",
        "**API**: Accuweather\n",
        "\n",
        "**Site oficial**: https://developer.accuweather.com/\n",
        "\n",
        "**Link para a documentação oficial**: https://developer.accuweather.com/accuweather-current-conditions-api/apis/get/currentconditions/v1/%7BlocationKey%7D\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DjJM_qhEZRy6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANTE**: cada **API** pode ser usada por até 4 equipes."
      ],
      "metadata": {
        "id": "bTODq98Myt_u"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtjgWQRzNphL"
      },
      "source": [
        "### **DESCRIÇÃO**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementar um `notebook` no `Google Colab` que faça uso do framework **`LangChain`** (obrigatório) e de um **LLM** aplicando, no mínimo, DUAS técnicas de PLN. As técnicas podem ser aplicada em qualquer córpus obtido a partir de uma **API** ou a partir de uma página Web.\n",
        "\n",
        "O **LLM** e a **API** selecionados devem ser informados na seguinte planilha:\n",
        "\n",
        "> https://docs.google.com/spreadsheets/d/1iIUZcwnywO7RuF6VEJ8Rx9NDT1cwteyvsnkhYr0NWtU/edit?usp=sharing\n",
        "\n",
        ">\n",
        "As seguintes técnicas de PLN podem ser usadas:\n",
        "\n",
        "*   Correção Gramatical\n",
        "*   Classificação de Textos\n",
        "*   Análise de Sentimentos\n",
        "*   Detecção de Emoções\n",
        "*   Extração de Palavras-chave\n",
        "*   Tradução de Textos\n",
        "*   Sumarização de Textos\n",
        "*   Similaridade de Textos\n",
        "*   Reconhecimento de Entidades Nomeadas\n",
        "*   Sistemas de Perguntas e Respostas\n",
        ">\n",
        "\n",
        "**IMPORTANTE:** É obrigatório usar o e-mail da UFABC.\n"
      ],
      "metadata": {
        "id": "fXTwkiiGs2BV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CRITÉRIOS DE AVALIAÇÃO**\n",
        "---\n"
      ],
      "metadata": {
        "id": "gWsBYQNtxmum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Serão considerados como critérios de avaliação os seguintes pontos:\n",
        "\n",
        "* Uso do framework **`LangChain`**.\n",
        "\n",
        "* Escolha e uso de um **LLM**.\n",
        "\n",
        "* Escolha e uso de uma **API**.\n",
        "\n",
        "* Vídeo (5 a 10 minutos).\n",
        "\n",
        "* Criatividade no uso do framework **`LangChain`** em conjunto com o **LLM** e a **API**.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5iHdx4BXYruQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANTE**: todo o código do notebook deve ser executado. Código sem execução não será considerado."
      ],
      "metadata": {
        "id": "LhwdrMp123Xx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **IMPLEMENTAÇÃO**\n",
        "---"
      ],
      "metadata": {
        "id": "nw09lujGvfjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conexão com a API"
      ],
      "metadata": {
        "id": "2yP55g3nb6hH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalar a biblioteca requests para fazer requisições HTTP com REST APIs."
      ],
      "metadata": {
        "id": "M_pceh9wTEth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests -qU"
      ],
      "metadata": {
        "id": "RyUailD5vi9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizamos a API pública da AccuWeather (https://developer.accuweather.com/) que retorna as condições climáticas atuais para um local específico.\n",
        "\n",
        "Os detalhes da API estão disponíveis em (https://developer.accuweather.com/accuweather-current-conditions-api/apis/get/currentconditions/v1/%7BlocationKey%7D). Nesse caso específico utilizamos o endpoint Current Conditions."
      ],
      "metadata": {
        "id": "HAhymPeuUkx7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANTE:** Nessa versão, que é a gratuita a API do AccuWeather comporta no máximo 50 requisições por dia."
      ],
      "metadata": {
        "id": "T0SlAO3bW4s2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A classe AccuWeatherAPI fornece uma interface simples para acessar informações de previsão do tempo da API AccuWeather. O método get_location_key permite recuperar a chave de uma cidade específica, que é usada para consultas futuras. O método get_forecast retorna as condições climáticas detalhadas para um determinado local, usando a chave da cidade. O método interpret_weather processa os dados da previsão e fornece um resumo interpretativo das condições climáticas, incluindo temperatura, precipitação, radiação UV e umidade relativa, oferecendo conselhos práticos como recomendações para proteção UV e atividades ao ar livre."
      ],
      "metadata": {
        "id": "oJeK9N8tTYJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Essas inferências em relação as condições climáticas são geradas via regras no código seguindo informações disponíveis publicamente (https://www.who.int/news-room/questions-and-answers/item/radiation-the-ultraviolet-(uv)-index e https://www.cgesp.org/v3/umidade-relativa-do-ar.jsp) assim o modelo utilizado não precisa inventar informações, o que melhora a precisão das respostas."
      ],
      "metadata": {
        "id": "AqTH1S1hTwtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "class AccuWeatherAPI:\n",
        "    def __init__(self, api_key):\n",
        "        self.api_key = api_key\n",
        "        self.base_url = \"http://dataservice.accuweather.com\"\n",
        "\n",
        "    def get_location_key(self, city_name):\n",
        "        \"\"\"Obter a chave de uma cidade específica\"\"\"\n",
        "        url = f\"{self.base_url}/locations/v1/cities/search\"\n",
        "        params = {\"apikey\": self.api_key, \"q\": city_name}\n",
        "        response = requests.get(url, params=params)\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            if data:\n",
        "                return data[0]['Key']\n",
        "        return None\n",
        "\n",
        "    def get_forecast(self, location_key):\n",
        "        \"\"\"Obter a previsão do tempo detalhada para um local específico\"\"\"\n",
        "        url = f\"{self.base_url}/currentconditions/v1/{location_key}\"\n",
        "        params = {\"apikey\": self.api_key, \"details\": True}\n",
        "        response = requests.get(url, params=params)\n",
        "        if response.status_code == 200:\n",
        "            return response.json()\n",
        "        else:\n",
        "            print(f\"Error: {response.status_code}, {response.text}\")\n",
        "            return None\n",
        "\n",
        "\n",
        "    \"\"\"Inferências geradas com base nas informações climáticas obtidas.\"\"\"\n",
        "    def interpret_weather(self, forecast):\n",
        "        \"\"\"Consolidar informações chave para interpretação pelo LLM\"\"\"\n",
        "        weather_text = forecast[0].get('WeatherText', 'Unknown')\n",
        "        temperature = forecast[0]['Temperature']['Metric']['Value']\n",
        "        has_precipitation = forecast[0]['HasPrecipitation']\n",
        "        precipitation_type = forecast[0].get('PrecipitationType', 'None')\n",
        "        is_daytime = forecast[0]['IsDayTime']\n",
        "        uv_index = forecast[0]['UVIndex']\n",
        "        relative_humidity = forecast[0]['RelativeHumidity']\n",
        "\n",
        "        weather_description = f\"The weather is currently {weather_text} with a temperature of {temperature}°C.\"\n",
        "\n",
        "        if has_precipitation:\n",
        "            weather_description += f\" There is {precipitation_type}.\"\n",
        "        else:\n",
        "            weather_description += \" No precipitation is expected.\"\n",
        "\n",
        "        \"\"\"As recomendações para se proteger contra a radiação UV nociva do sol vem de: https://www.who.int/news-room/questions-and-answers/item/radiation-the-ultraviolet-(uv)-index\"\"\"\n",
        "        uv_description = \"\"\n",
        "        if uv_index <= 2:\n",
        "            uv_description = \"Low - You can safely enjoy being outside!\"\n",
        "        elif uv_index <= 7:\n",
        "            uv_description = \"Moderate - Seek shade during midday hours! Slip on a shirt, slop on sunscreen and slap on a hat!\"\n",
        "        else:\n",
        "            uv_description = \"High - Avoid being outside during midday hours! Make sure you seek shade! Shirt, sunscreen, and hat are a must!\"\n",
        "\n",
        "        \"\"\"Dados sobre a escala de umidade relativa do ar obtidos de: https://www.cgesp.org/v3/umidade-relativa-do-ar.jsp\"\"\"\n",
        "        humidity_description = \"\"\n",
        "        if relative_humidity < 12:\n",
        "            humidity_description = \"Critically low - Uncomfortably dry\"\n",
        "        if relative_humidity < 30:\n",
        "            humidity_description = \"Low - Dry\"\n",
        "        elif relative_humidity < 70:\n",
        "            humidity_description = \"Moderate - Comfortable\"\n",
        "        else:\n",
        "            humidity_description = \"High - Uncomfortably humid\"\n",
        "\n",
        "        return {\n",
        "            'temperature': f\"{temperature} °C\",\n",
        "            'weather_text': weather_text,\n",
        "            'is_daytime': is_daytime,\n",
        "            'weather_description': weather_description,\n",
        "            'has_precipitation': has_precipitation,\n",
        "            'precipitation_type': precipitation_type,\n",
        "            'rain_today': has_precipitation and precipitation_type.lower() == 'rain',\n",
        "            'umbrella_advice': has_precipitation and is_daytime,\n",
        "            'uv_index': uv_index,\n",
        "            'uv_description': uv_description,\n",
        "            'relative_humidity': relative_humidity,\n",
        "            'humidity_description': humidity_description,\n",
        "            'activity_advice': not has_precipitation and humidity_description == 'Moderate - Comfortable' and float(str(temperature).split()[0])  > 20,\n",
        "        }"
      ],
      "metadata": {
        "id": "diH5E6dmN4UM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain + Google Gemini"
      ],
      "metadata": {
        "id": "rMmSk7q7EvmU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Engenharia de prompt\n",
        "\n",
        "Instalando a biblioteca LangChain"
      ],
      "metadata": {
        "id": "NguDsAfPFZa5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain -qU"
      ],
      "metadata": {
        "id": "N9BbOUh7mEf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui definimos um template para o prompt visando padronizar a leitura, feita pelo modelo, das perguntas do usuário."
      ],
      "metadata": {
        "id": "HOZ0UPA4Xzo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Cria um template de prompt dinâmico\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"query\", \"temp\", \"weather_text\", \"is_daytime\", \"weather_description\", \"has_preciptation\", \"precipitation_type\",\n",
        "                     \"rain_today\", \"umbrella_advice\", \"uv_index\", \"uv_description\", \"relative_humidity\", \"humidity_description\", \"activity_advice\"],\n",
        "    template=\"\"\"\n",
        "    You are a weather assistant. The user asked: \"{query}\"\n",
        "\n",
        "    Based on the following data:\n",
        "    Temperature: {temp},\n",
        "    Conditions: {weather_text},\n",
        "    Is it daytime?: {is_daytime},\n",
        "    Weather summary: {weather_description},\n",
        "    Precipitation?: {has_precipitation},\n",
        "    Precipitation type: {precipitation_type},\n",
        "    Will it rain?: {rain_today},\n",
        "    Is it recommended to bring an umbrella?: {umbrella_advice},\n",
        "    UV Index: {uv_index},\n",
        "    UV recommendation: {uv_description},\n",
        "    Relative humidity: {relative_humidity},\n",
        "    Relative humidity classification: {humidity_description},\n",
        "    Is it recommended to practice outside activities/sports?: {activity_advice}\n",
        "\n",
        "    Please respond naturally to the user's question.\n",
        "    \"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "Q0X5A8tDmB6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este método cria um dicionário de dados com as varáveis climáticas obtidas e a pergunta do usuário"
      ],
      "metadata": {
        "id": "xX3B2knVYCtS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar um dicionário de dados com as varáveis climáticas obtidas e a pergunta do usuário\n",
        "\n",
        "def set_prompt_values(query, weather_info):\n",
        "  prompt_values = {\n",
        "      \"query\": query,\n",
        "      \"temp\": weather_info['temperature'],\n",
        "      \"weather_text\": weather_info['weather_text'],\n",
        "      \"is_daytime\": \"Yes\" if weather_info['is_daytime'] else \"No\",\n",
        "      \"weather_description\": weather_info['weather_description'],\n",
        "      \"has_precipitation\": \"Yes\" if weather_info['has_precipitation'] else \"No\",\n",
        "      \"precipitation_type\": weather_info['precipitation_type'],\n",
        "      \"rain_today\": \"Yes\" if weather_info['rain_today'] else \"No\",\n",
        "      \"umbrella_advice\": \"Yes\" if weather_info['umbrella_advice'] else \"No\",\n",
        "      \"uv_index\": weather_info['uv_index'],\n",
        "      \"uv_description\": weather_info['uv_description'],\n",
        "      \"relative_humidity\": weather_info['relative_humidity'],\n",
        "      \"humidity_description\": weather_info['humidity_description'],\n",
        "      \"activity_advice\": \"Yes\" if weather_info['activity_advice'] else \"No\",\n",
        "  }\n",
        "\n",
        "  prompt = prompt_template.format(**prompt_values)\n",
        "\n",
        "  return prompt"
      ],
      "metadata": {
        "id": "R4fA8PnPn6-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conexão com o modelo"
      ],
      "metadata": {
        "id": "ER99hbJwE_T-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalar ou atualizar o pacote langchain-google-genai, que é uma integração da biblioteca LangChain com os modelos de inteligência artificial da Google."
      ],
      "metadata": {
        "id": "jTY5nRLVWieM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalando o pacote langchain-google-genai\n",
        "!pip install langchain-google-genai -qU"
      ],
      "metadata": {
        "id": "qSNR5YFLlo4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurar a classe Model para interagir com a API Generative AI do Google, usando o modelo gemini-1.5-flash da biblioteca langchain_google_genai. O construtor da classe (__init__) define a chave de autenticação da API no ambiente e inicializa o modelo de geração de texto. A classe oferece dois métodos principais: make_request, que envia um prompt para o modelo e retorna a resposta, e traduzir_texto, que traduz um texto de um idioma para outro. O método traduzir_texto cria um prompt específico para tradução e utiliza make_request para obter e retornar a tradução solicitada."
      ],
      "metadata": {
        "id": "-IAn0ldDWst3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A chave da API do Google está definida no código para facilitar as operações."
      ],
      "metadata": {
        "id": "Z9wHxwiKWwxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "class Model():\n",
        "    def __init__(self):\n",
        "        # Inserir a chave de autenticação para acessar a API Generative AI do Google\n",
        "        os.environ[\"GOOGLE_API_KEY\"] = 'AIzaSyBDkdkjXzYQykd2OPSkvtbUI7D1DNKkUVM'\n",
        "\n",
        "        # Utilizar o modelo gemini-1.5-flash\n",
        "        self.modelo = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
        "\n",
        "    def make_request(self, prompt):\n",
        "      resposta = self.modelo.invoke(prompt)\n",
        "      return resposta\n",
        "\n",
        "    def traduzir_texto(self, texto, idioma_origem=\"pt-br\", idioma_destino=\"en-us\"):\n",
        "        # Cria o prompt de tradução\n",
        "        prompt = f\"\"\"\n",
        "            You are a language translator.\n",
        "            Translate the following text from {idioma_origem} to {idioma_destino}: '{texto}'.\n",
        "            Respond with the translated text only.\n",
        "        \"\"\"\n",
        "\n",
        "        # Faz a requisição ao modelo para a tradução\n",
        "        traducao = self.make_request(prompt)\n",
        "        return traducao"
      ],
      "metadata": {
        "id": "oKGXR_FXqAv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat"
      ],
      "metadata": {
        "id": "9CDfaEDiE1L1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código define uma classe chamada ChatModel, que é responsável por gerenciar uma conversa focada em perguntas sobre o clima. Ele traduz perguntas feitas pelo usuário em português para o inglês, envia as perguntas ao modelo e guarda o histórico de interações do chat, e depois traduz a resposta também para o português.\n",
        "\n",
        "Aqui está como ele funciona de forma geral:\n",
        "\n",
        "- Iniciação da Classe: Quando a classe ChatModel é criada, ela carrega um modelo de linguagem e um histórico de perguntas e respostas que só envolve questões sobre o clima.\n",
        "\n",
        "- Histórico de Conversas: O código mantém um registro de todas as perguntas e respostas relacionadas ao clima em uma lista, que pode ser consultada para dar contexto às respostas futuras do modelo.\n",
        "\n",
        "- Geração de Perguntas: Quando o usuário faz uma pergunta sobre o clima, essa pergunta é traduzida para o inglês (já que o modelo parece funcionar melhor em inglês), e um prompt é criado. Esse prompt inclui tanto a pergunta do usuário quanto o histórico de interações anteriores, além de informações adicionais sobre o clima.\n",
        "\n",
        "- Resposta do Modelo: O prompt gerado é enviado ao modelo, que responde com base no contexto dado. Essa resposta, inicialmente em inglês, é então traduzida de volta para o português para ser exibida ao usuário.\n",
        "\n",
        "- Ciclo de Conversa: O programa continua em um loop, onde o usuário pode continuar fazendo perguntas sobre o clima. A cada interação, a pergunta e a resposta são adicionadas ao histórico, permitindo que o modelo entenda melhor o contexto das conversas passadas e forneça respostas mais precisas."
      ],
      "metadata": {
        "id": "KXH6eN2jUZwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatModel:\n",
        "    def __init__(self):\n",
        "        self.model = Model()\n",
        "        self.weather_history = []  # Apenas perguntas e respostas sobre o clima\n",
        "\n",
        "    def add_to_history(self, user_message, model_response):\n",
        "        # Adicionar ao histórico somente as perguntas e respostas sobre o clima\n",
        "        self.weather_history.append(f\"User: {user_message}\")\n",
        "        self.weather_history.append(f\"Model: {model_response}\")\n",
        "\n",
        "    def generate_prompt(self, user_question, weather_info):\n",
        "        # Traduzir a pergunta do usuário para o inglês\n",
        "        question_in_english = self.model.traduzir_texto(texto=user_question, idioma_origem=\"pt-br\", idioma_destino=\"en-us\")\n",
        "        question_in_english = question_in_english.content\n",
        "        # Criar o prompt com base nas informações do clima e no histórico\n",
        "        history_text = \"\\n\".join(self.weather_history)\n",
        "        prompt = f\"{history_text}\\nUser: {question_in_english}\\nWeather info: {weather_info}\\nModel:\"\n",
        "\n",
        "        return prompt, question_in_english  # Retorna a pergunta em inglês para adicionar ao histórico\n",
        "\n",
        "    def get_response(self, prompt):\n",
        "        # Fazer a requisição ao modelo\n",
        "        response = self.model.make_request(prompt)\n",
        "\n",
        "        # Verificar o tipo da resposta e acessar o campo content\n",
        "        if hasattr(response, 'content'):\n",
        "            response_content = response.content\n",
        "        else:\n",
        "            response_content = str(response)  # Assumindo que seja uma string ou outro tipo\n",
        "\n",
        "        # Traduzir a resposta para o português\n",
        "        response_in_portuguese = self.model.traduzir_texto(response_content, idioma_origem=\"en-us\", idioma_destino=\"pt-br\")\n",
        "\n",
        "        return response_content, response_in_portuguese  # Retorna as duas versões da resposta\n",
        "\n",
        "    def chat(self, weather_info):\n",
        "        while True:\n",
        "            user_question = input(\"Digite sua pergunta sobre o clima: \")\n",
        "\n",
        "            # Gera o prompt e obtém a resposta\n",
        "            prompt, question_in_english = self.generate_prompt(user_question, weather_info)\n",
        "\n",
        "            # Não há necessidade de acessar .content, pois question_in_english é uma string\n",
        "            response_in_english, response_in_portuguese = self.get_response(prompt)\n",
        "\n",
        "            # Adicionar somente a pergunta sobre o clima e a resposta ao histórico\n",
        "            self.add_to_history(question_in_english, response_in_english)\n",
        "\n",
        "            # Exibir a resposta ao usuário\n",
        "            print(response_in_portuguese.content)"
      ],
      "metadata": {
        "id": "s4bPNY4e6p_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aplicação"
      ],
      "metadata": {
        "id": "TU--8Xj9uj91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de uso no fluxo do programa\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        accuweather = AccuWeatherAPI(\"9xhyFBB8RZXhrWyQhGgh4o5GTfo54qgu\")\n",
        "        location_key = accuweather.get_location_key(\"São Paulo\")\n",
        "        forecast = accuweather.get_forecast(location_key)\n",
        "        weather_info = accuweather.interpret_weather(forecast)\n",
        "\n",
        "        chat_model = ChatModel()\n",
        "        chat_model.chat(weather_info)\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nProgram interrupted by user. Exiting gracefully...\")\n",
        "    finally:\n",
        "        # Saindo do programa\n",
        "        print(\"Cleanup if needed.\")\n"
      ],
      "metadata": {
        "id": "GmsqAOjKs-ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f149446-6861-4b24-f41e-faa15e7990bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Digite sua pergunta sobre o clima: Como está o céu agora, e como está a temperatura?\n",
            "O céu está limpo e a temperatura é de 23,9°C. \n",
            "\n",
            "\n",
            "Program interrupted by user. Exiting gracefully...\n",
            "Cleanup if needed.\n"
          ]
        }
      ]
    }
  ]
}